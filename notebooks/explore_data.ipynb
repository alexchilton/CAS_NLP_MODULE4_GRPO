{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordle GRPO Data Exploration\n",
    "\n",
    "This notebook explores the Wordle GRPO datasets and helps understand:\n",
    "- Dataset structure and format\n",
    "- Expected input/output formats for the model\n",
    "- How reward functions work on real examples\n",
    "- Word list statistics and patterns\n",
    "- What the model needs to learn\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets\n",
    "\n",
    "We'll load both the GRPO training dataset and the SFT reference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load datasets\n",
    "data_dir = project_root / \"data\" / \"cache\"\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "print(\"This may take a moment on first run...\\n\")\n",
    "\n",
    "try:\n",
    "    grpo_dataset = load_dataset(\n",
    "        \"predibase/wordle-grpo\",\n",
    "        cache_dir=str(data_dir),\n",
    "        download_mode=\"reuse_dataset_if_exists\"\n",
    "    )\n",
    "    print(\"✓ GRPO dataset loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading GRPO dataset: {e}\")\n",
    "    print(\"Run: python scripts/download_data.py\")\n",
    "    grpo_dataset = None\n",
    "\n",
    "try:\n",
    "    sft_dataset = load_dataset(\n",
    "        \"predibase/wordle-sft\",\n",
    "        cache_dir=str(data_dir),\n",
    "        download_mode=\"reuse_dataset_if_exists\"\n",
    "    )\n",
    "    print(\"✓ SFT dataset loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading SFT dataset: {e}\")\n",
    "    print(\"Run: python scripts/download_data.py\")\n",
    "    sft_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "Let's examine the structure of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grpo_dataset:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GRPO Dataset Structure\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Splits: {list(grpo_dataset.keys())}\")\n",
    "    print()\n",
    "    \n",
    "    for split_name, split_data in grpo_dataset.items():\n",
    "        print(f\"{split_name.upper()}:\")\n",
    "        print(f\"  Size: {len(split_data)} examples\")\n",
    "        print(f\"  Columns: {split_data.column_names}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sft_dataset:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SFT Dataset Structure\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Splits: {list(sft_dataset.keys())}\")\n",
    "    print()\n",
    "    \n",
    "    for split_name, split_data in sft_dataset.items():\n",
    "        print(f\"{split_name.upper()}:\")\n",
    "        print(f\"  Size: {len(split_data)} examples\")\n",
    "        print(f\"  Columns: {split_data.column_names}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Examples\n",
    "\n",
    "Let's look at actual examples to understand the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grpo_dataset:\n",
    "    # Get first split\n",
    "    split_name = list(grpo_dataset.keys())[0]\n",
    "    split_data = grpo_dataset[split_name]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Sample Example from GRPO Dataset ({split_name} split)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    example = split_data[0]\n",
    "    \n",
    "    for key, value in example.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Pretty print based on type\n",
    "        if isinstance(value, str):\n",
    "            # Truncate long strings\n",
    "            if len(value) > 500:\n",
    "                print(value[:500] + \"\\n... (truncated)\")\n",
    "            else:\n",
    "                print(value)\n",
    "        elif isinstance(value, (list, dict)):\n",
    "            print(json.dumps(value, indent=2))\n",
    "        else:\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Multiple Examples\n",
    "\n",
    "Let's look at a few more examples to see the variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grpo_dataset:\n",
    "    split_data = grpo_dataset[list(grpo_dataset.keys())[0]]\n",
    "    \n",
    "    # Show 3 examples\n",
    "    for i in range(min(3, len(split_data))):\n",
    "        example = split_data[i]\n",
    "        \n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Example {i+1}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Show key information\n",
    "        if 'prompt' in example:\n",
    "            prompt_preview = example['prompt'][:200] if len(example['prompt']) > 200 else example['prompt']\n",
    "            print(f\"Prompt (preview): {prompt_preview}...\")\n",
    "            print()\n",
    "        \n",
    "        if 'past_guess_history' in example:\n",
    "            print(f\"Past guess history: {example['past_guess_history']}\")\n",
    "            print()\n",
    "        \n",
    "        if 'word_list' in example:\n",
    "            word_list = example['word_list']\n",
    "            if isinstance(word_list, list):\n",
    "                print(f\"Word list size: {len(word_list)}\")\n",
    "                print(f\"Sample words: {word_list[:10]}\")\n",
    "            else:\n",
    "                print(f\"Word list: {word_list}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Past Guess History Structure\n",
    "\n",
    "The `past_guess_history` contains previous guesses and their feedback. This is crucial for the model to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grpo_dataset:\n",
    "    split_data = grpo_dataset[list(grpo_dataset.keys())[0]]\n",
    "    \n",
    "    # Collect guess history statistics\n",
    "    history_lengths = []\n",
    "    \n",
    "    for example in split_data:\n",
    "        if 'past_guess_history' in example:\n",
    "            history = example['past_guess_history']\n",
    "            if isinstance(history, list):\n",
    "                history_lengths.append(len(history))\n",
    "            elif isinstance(history, str) and history:\n",
    "                # Might be stored as string\n",
    "                history_lengths.append(1)\n",
    "            else:\n",
    "                history_lengths.append(0)\n",
    "    \n",
    "    # Visualize distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(history_lengths, bins=range(0, max(history_lengths) + 2), alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Number of Previous Guesses')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Past Guess History Lengths')\n",
    "    plt.xticks(range(0, max(history_lengths) + 1))\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Statistics:\")\n",
    "    print(f\"  Mean history length: {np.mean(history_lengths):.2f}\")\n",
    "    print(f\"  Median history length: {np.median(history_lengths):.0f}\")\n",
    "    print(f\"  Max history length: {max(history_lengths)}\")\n",
    "    print(f\"  Examples with no history: {history_lengths.count(0)} ({history_lengths.count(0)/len(history_lengths)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Example Guess Histories\n",
    "\n",
    "Let's look at the structure of actual guess histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grpo_dataset:\n",
    "    split_data = grpo_dataset[list(grpo_dataset.keys())[0]]\n",
    "    \n",
    "    # Find examples with different history lengths\n",
    "    examples_by_length = defaultdict(list)\n",
    "    \n",
    "    for i, example in enumerate(split_data):\n",
    "        if 'past_guess_history' in example:\n",
    "            history = example['past_guess_history']\n",
    "            length = len(history) if isinstance(history, list) else (1 if history else 0)\n",
    "            examples_by_length[length].append(i)\n",
    "    \n",
    "    # Show examples with 0, 1, 2, 3 previous guesses\n",
    "    for num_guesses in [0, 1, 2, 3]:\n",
    "        if num_guesses in examples_by_length and examples_by_length[num_guesses]:\n",
    "            idx = examples_by_length[num_guesses][0]\n",
    "            example = split_data[idx]\n",
    "            \n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"Example with {num_guesses} previous guess(es)\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            if 'past_guess_history' in example:\n",
    "                history = example['past_guess_history']\n",
    "                print(f\"History: {json.dumps(history, indent=2)}\")\n",
    "            \n",
    "            if 'prompt' in example:\n",
    "                prompt_preview = example['prompt'][:300]\n",
    "                print(f\"\\nPrompt preview:\\n{prompt_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Reward Functions\n",
    "\n",
    "Let's test our reward functions on real examples to understand how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.reward_functions import (\n",
    "    output_format_check,\n",
    "    uses_previous_feedback,\n",
    "    guess_value,\n",
    "    CombinedReward\n",
    ")\n",
    "\n",
    "print(\"✓ Reward functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Output Format Check\n",
    "\n",
    "This reward function checks if the output follows the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different completion formats\n",
    "test_cases = [\n",
    "    {\n",
    "        \"name\": \"Perfect format\",\n",
    "        \"completion\": \"<think>Let me try a common starting word</think>\\n<guess>CRANE</guess>\",\n",
    "        \"example\": {\"word_list\": [\"CRANE\", \"TRAIN\", \"BRAIN\"]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Missing think tags\",\n",
    "        \"completion\": \"<guess>CRANE</guess>\",\n",
    "        \"example\": {\"word_list\": [\"CRANE\", \"TRAIN\", \"BRAIN\"]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Invalid word (not in list)\",\n",
    "        \"completion\": \"<think>Random guess</think>\\n<guess>ZZZZZ</guess>\",\n",
    "        \"example\": {\"word_list\": [\"CRANE\", \"TRAIN\", \"BRAIN\"]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Wrong length\",\n",
    "        \"completion\": \"<think>Too short</think>\\n<guess>CAT</guess>\",\n",
    "        \"example\": {\"word_list\": [\"CRANE\", \"TRAIN\", \"BRAIN\"]}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"No tags at all\",\n",
    "        \"completion\": \"I think CRANE is a good guess\",\n",
    "        \"example\": {\"word_list\": [\"CRANE\", \"TRAIN\", \"BRAIN\"]}\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Output Format Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test in test_cases:\n",
    "    reward = output_format_check(\"\", test[\"completion\"], test[\"example\"])\n",
    "    print(f\"\\n{test['name']}:\")\n",
    "    print(f\"  Completion: {test['completion'][:60]}...\")\n",
    "    print(f\"  Reward: {reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Uses Previous Feedback\n",
    "\n",
    "This reward function checks if the model uses information from previous guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different guess scenarios\n",
    "test_cases_feedback = [\n",
    "    {\n",
    "        \"name\": \"Keeps correct letter in position\",\n",
    "        \"completion\": \"<think>A was correct</think>\\n<guess>BRAIN</guess>\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [\n",
    "                {\"guess\": \"TRAIN\", \"feedback\": \"T(-) R(✓) A(✓) I(x) N(x)\"}\n",
    "            ],\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Uses wrong letter again (penalty)\",\n",
    "        \"completion\": \"<think>Trying again</think>\\n<guess>TRAIN</guess>\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [\n",
    "                {\"guess\": \"STAIN\", \"feedback\": \"S(x) T(x) A(✓) I(x) N(x)\"}\n",
    "            ],\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Tries misplaced letter in new position\",\n",
    "        \"completion\": \"<think>R was in wrong spot</think>\\n<guess>SIREN</guess>\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [\n",
    "                {\"guess\": \"TRAIN\", \"feedback\": \"T(x) R(-) A(x) I(x) N(x)\"}\n",
    "            ],\n",
    "            \"word_list\": [\"SIREN\", \"AFIRE\", \"BORED\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"First guess (no history)\",\n",
    "        \"completion\": \"<think>Starting word</think>\\n<guess>CRANE</guess>\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [],\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Uses Previous Feedback\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test in test_cases_feedback:\n",
    "    reward = uses_previous_feedback(\"\", test[\"completion\"], test[\"example\"])\n",
    "    print(f\"\\n{test['name']}:\")\n",
    "    if test['example']['past_guess_history']:\n",
    "        print(f\"  Previous: {test['example']['past_guess_history'][0]}\")\n",
    "    print(f\"  New guess: {test['completion'][test['completion'].find('<guess>')+7:test['completion'].find('</guess>')]}\")\n",
    "    print(f\"  Reward: {reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Guess Value (Information Gain)\n",
    "\n",
    "This reward function measures how much information a guess provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different word lists and guesses\n",
    "test_cases_value = [\n",
    "    {\n",
    "        \"name\": \"Good starting word (high entropy)\",\n",
    "        \"completion\": \"<think>CRANE has common letters</think>\\n<guess>CRANE</guess>\",\n",
    "        \"example\": {\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\", \"DRAIN\", \"TRAIN\", \"PLAIN\", \"SLAIN\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Repeated letters (lower entropy)\",\n",
    "        \"completion\": \"<think>Trying GEESE</think>\\n<guess>GEESE</guess>\",\n",
    "        \"example\": {\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\", \"DRAIN\", \"TRAIN\", \"PLAIN\", \"SLAIN\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Uncommon letters\",\n",
    "        \"completion\": \"<think>Testing Q and Z</think>\\n<guess>QUIZZ</guess>\",\n",
    "        \"example\": {\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\", \"DRAIN\", \"TRAIN\", \"PLAIN\", \"SLAIN\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Guess Value (Information Gain)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test in test_cases_value:\n",
    "    reward = guess_value(\"\", test[\"completion\"], test[\"example\"])\n",
    "    print(f\"\\n{test['name']}:\")\n",
    "    guess = test['completion'][test['completion'].find('<guess>')+7:test['completion'].find('</guess>')]\n",
    "    print(f\"  Guess: {guess}\")\n",
    "    print(f\"  Word list size: {len(test['example']['word_list'])}\")\n",
    "    print(f\"  Reward: {reward:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Combined Reward\n",
    "\n",
    "In practice, we combine all three reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reward = CombinedReward(\n",
    "    format_weight=1.0,\n",
    "    feedback_weight=0.5,\n",
    "    value_weight=0.3\n",
    ")\n",
    "\n",
    "# Test on a few examples\n",
    "test_cases_combined = [\n",
    "    {\n",
    "        \"name\": \"Perfect guess\",\n",
    "        \"completion\": \"<think>Keeping R and A in correct positions</think>\\n<guess>GRAIN</guess>\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [\n",
    "                {\"guess\": \"TRAIN\", \"feedback\": \"T(x) R(✓) A(✓) I(x) N(x)\"}\n",
    "            ],\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\", \"DRAIN\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bad format\",\n",
    "        \"completion\": \"I think GRAIN\",\n",
    "        \"example\": {\n",
    "            \"past_guess_history\": [\n",
    "                {\"guess\": \"TRAIN\", \"feedback\": \"T(x) R(✓) A(✓) I(x) N(x)\"}\n",
    "            ],\n",
    "            \"word_list\": [\"CRANE\", \"BRAIN\", \"GRAIN\", \"DRAIN\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Combined Reward\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Weights: format={combined_reward.format_weight}, \"\n",
    "      f\"feedback={combined_reward.feedback_weight}, \"\n",
    "      f\"value={combined_reward.value_weight}\\n\")\n",
    "\n",
    "for test in test_cases_combined:\n",
    "    total_reward = combined_reward(\"\", test[\"completion\"], test[\"example\"])\n",
    "    \n",
    "    # Also show individual components\n",
    "    format_r = output_format_check(\"\", test[\"completion\"], test[\"example\"])\n",
    "    feedback_r = uses_previous_feedback(\"\", test[\"completion\"], test[\"example\"])\n",
    "    value_r = guess_value(\"\", test[\"completion\"], test[\"example\"])\n",
    "    \n",
    "    print(f\"\\n{test['name']}:\")\n",
    "    print(f\"  Completion: {test['completion'][:60]}...\")\n",
    "    print(f\"  Format reward: {format_r:.2f}\")\n",
    "    print(f\"  Feedback reward: {feedback_r:.2f}\")\n",
    "    print(f\"  Value reward: {value_r:.3f}\")\n",
    "    print(f\"  TOTAL REWARD: {total_reward:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Word List Analysis\n",
    "\n",
    "Let's analyze the word lists to understand what words the model needs to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique words from dataset\n",
    "all_words = set()\n",
    "\n",
    "if grpo_dataset:\n",
    "    for split_name, split_data in grpo_dataset.items():\n",
    "        for example in split_data:\n",
    "            if 'word_list' in example and isinstance(example['word_list'], list):\n",
    "                all_words.update(example['word_list'])\n",
    "\n",
    "print(f\"Total unique words: {len(all_words)}\")\n",
    "print(f\"Sample words: {list(all_words)[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_words:\n",
    "    # Count letter frequencies\n",
    "    letter_counts = Counter()\n",
    "    position_counts = [Counter() for _ in range(5)]\n",
    "    \n",
    "    for word in all_words:\n",
    "        for i, letter in enumerate(word.upper()):\n",
    "            letter_counts[letter] += 1\n",
    "            if i < 5:\n",
    "                position_counts[i][letter] += 1\n",
    "    \n",
    "    # Plot overall letter frequency\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    letters, counts = zip(*letter_counts.most_common())\n",
    "    plt.bar(letters, counts, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Letter')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Overall Letter Frequency in Word List')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot position-specific frequency for common letters\n",
    "    plt.subplot(1, 2, 2)\n",
    "    top_letters = [l for l, _ in letter_counts.most_common(10)]\n",
    "    \n",
    "    position_data = []\n",
    "    for letter in top_letters:\n",
    "        position_data.append([position_counts[i][letter] for i in range(5)])\n",
    "    \n",
    "    x = np.arange(5)\n",
    "    width = 0.08\n",
    "    \n",
    "    for i, letter in enumerate(top_letters):\n",
    "        offset = width * (i - len(top_letters)/2)\n",
    "        plt.bar(x + offset, position_data[i], width, label=letter, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Top 10 Letters by Position')\n",
    "    plt.xticks(x, ['1st', '2nd', '3rd', '4th', '5th'])\n",
    "    plt.legend(ncol=2)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMost common letters:\")\n",
    "    for letter, count in letter_counts.most_common(10):\n",
    "        print(f\"  {letter}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Starting Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_words:\n",
    "    # Analyze first letters\n",
    "    first_letters = Counter(word[0] for word in all_words if len(word) >= 5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    letters, counts = zip(*sorted(first_letters.items()))\n",
    "    plt.bar(letters, counts, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "    plt.xlabel('First Letter')\n",
    "    plt.ylabel('Number of Words')\n",
    "    plt.title('Distribution of First Letters')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMost common starting letters:\")\n",
    "    for letter, count in first_letters.most_common(10):\n",
    "        print(f\"  {letter}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vowel vs Consonant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_words:\n",
    "    vowels = set('AEIOU')\n",
    "    \n",
    "    # Count vowels per word\n",
    "    vowel_counts = Counter()\n",
    "    for word in all_words:\n",
    "        num_vowels = sum(1 for letter in word.upper() if letter in vowels)\n",
    "        vowel_counts[num_vowels] += 1\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    counts_list = [vowel_counts[i] for i in range(6)]\n",
    "    plt.bar(range(6), counts_list, alpha=0.7, edgecolor='black', color='coral')\n",
    "    plt.xlabel('Number of Vowels')\n",
    "    plt.ylabel('Number of Words')\n",
    "    plt.title('Distribution of Vowel Count in Words')\n",
    "    plt.xticks(range(6))\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nVowel distribution:\")\n",
    "    for num_vowels in range(6):\n",
    "        count = vowel_counts[num_vowels]\n",
    "        pct = count / len(all_words) * 100\n",
    "        print(f\"  {num_vowels} vowels: {count} words ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What the Model Needs to Learn\n",
    "\n",
    "Based on our exploration, here's what the model needs to learn:\n",
    "\n",
    "### 1. **Output Format**\n",
    "- Always use `<think>...</think><guess>...</guess>` tags\n",
    "- Guess must be exactly 5 letters\n",
    "- Guess must be from the valid word list\n",
    "\n",
    "### 2. **Using Feedback**\n",
    "- Keep letters marked as correct (✓) in the same position\n",
    "- Try misplaced letters (-) in different positions\n",
    "- Avoid letters marked as wrong (x)\n",
    "- Explore new letters when appropriate\n",
    "\n",
    "### 3. **Strategic Guessing**\n",
    "- Choose words that maximize information gain\n",
    "- Use common letters in starting guesses\n",
    "- Consider letter frequency and position\n",
    "- Balance exploration vs exploitation\n",
    "\n",
    "### 4. **Game State Understanding**\n",
    "- Track what's been guessed before\n",
    "- Narrow down possibilities based on feedback\n",
    "- Make logical deductions from constraints\n",
    "\n",
    "Let's visualize the learning objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Reward components\n",
    "ax = axes[0, 0]\n",
    "components = ['Format', 'Feedback', 'Value']\n",
    "weights = [1.0, 0.5, 0.3]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "ax.bar(components, weights, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Reward Function Components')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Learning progression\n",
    "ax = axes[0, 1]\n",
    "stages = ['Format\\nLearning', 'Feedback\\nUsage', 'Strategic\\nGuessing', 'Optimal\\nPlay']\n",
    "difficulty = [1, 2, 3, 4]\n",
    "ax.plot(stages, difficulty, marker='o', linewidth=2, markersize=10, color='#FF6B6B')\n",
    "ax.fill_between(range(len(stages)), difficulty, alpha=0.3, color='#FF6B6B')\n",
    "ax.set_ylabel('Complexity')\n",
    "ax.set_title('Learning Progression')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Expected win rate by guess number\n",
    "ax = axes[1, 0]\n",
    "guess_numbers = [1, 2, 3, 4, 5, 6]\n",
    "# Rough estimates for visualization\n",
    "expected_wins = [0.001, 0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "ax.bar(guess_numbers, expected_wins, alpha=0.7, color='#4ECDC4', edgecolor='black')\n",
    "ax.set_xlabel('Guess Number')\n",
    "ax.set_ylabel('Cumulative Win Probability')\n",
    "ax.set_title('Expected Win Rate by Guess (Target)')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Training objectives\n",
    "ax = axes[1, 1]\n",
    "objectives = ['Valid\\nFormat', 'Use\\nFeedback', 'High\\nEntropy', 'Win\\nGames']\n",
    "importance = [10, 8, 6, 9]\n",
    "ax.barh(objectives, importance, alpha=0.7, color='#45B7D1', edgecolor='black')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Training Objectives')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. The model must first learn valid output format (strict requirement)\")\n",
    "print(\"2. Then learn to use feedback from previous guesses\")\n",
    "print(\"3. Finally optimize for information gain (entropy)\")\n",
    "print(\"4. Success = combining all three objectives\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics\n",
    "\n",
    "Let's compile final summary statistics about our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if grpo_dataset:\n",
    "    print(\"\\nGRPO Dataset:\")\n",
    "    total_examples = sum(len(split) for split in grpo_dataset.values())\n",
    "    print(f\"  Total examples: {total_examples}\")\n",
    "    for split_name, split_data in grpo_dataset.items():\n",
    "        print(f\"  {split_name}: {len(split_data)}\")\n",
    "\n",
    "if sft_dataset:\n",
    "    print(\"\\nSFT Dataset:\")\n",
    "    total_examples = sum(len(split) for split in sft_dataset.values())\n",
    "    print(f\"  Total examples: {total_examples}\")\n",
    "    for split_name, split_data in sft_dataset.items():\n",
    "        print(f\"  {split_name}: {len(split_data)}\")\n",
    "\n",
    "if all_words:\n",
    "    print(\"\\nWord List:\")\n",
    "    print(f\"  Unique words: {len(all_words)}\")\n",
    "    print(f\"  Letter frequency (top 5): {', '.join([f'{l}:{c}' for l, c in letter_counts.most_common(5)])}\")\n",
    "\n",
    "print(\"\\nReward Functions:\")\n",
    "print(\"  1. output_format_check: 0.0 to 1.0\")\n",
    "print(\"  2. uses_previous_feedback: variable (can be negative)\")\n",
    "print(\"  3. guess_value: 0.0 to 1.0 (normalized entropy)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready for training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand the data:\n",
    "\n",
    "1. **Run the setup test**: `python scripts/test_setup.py`\n",
    "2. **Start training**: `python scripts/train.py --config configs/dev_config.yaml`\n",
    "3. **Monitor rewards**: Watch how the three reward components improve\n",
    "4. **Evaluate**: Test the trained model with `python scripts/evaluate.py`\n",
    "\n",
    "The model should progressively learn:\n",
    "- First: Valid format (reward ~1.0)\n",
    "- Then: Using feedback (positive feedback rewards)\n",
    "- Finally: Strategic guessing (high entropy rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
